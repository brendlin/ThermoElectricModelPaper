We have developed a model of the ATLAS ITk strip system which is based on the interplay between a thermal and an electrical network model. The set of equations in the model can be numerically solved using standard data analysis software in short time, allowing for a quick turn-around for systematic studies of the system performance. The complexity of these networks is given by the number of interconnected components between the networks which have a non-linear dependence on the temperature or electrical power. This approach could easily be adopted for any other silicon detector system.

In the case of the ATLAS strip system several temperature-dependent heat sources had to be included. In addition to the sensor leakage current these are the  radiation-induced increase of the digital front-end power (`TID bump') and the efficiency of the DC/DC conversion system. The outputs of the model give us confidence that the ITk strip system will be thermally stable until the end of LHC phase II operation even if safety factors on key inputs are included. The model furthermore provides information for benchmark system parameters like cooling and supply power and currents in power cables, which is used in the specification of these systems. The use of the model outputs throughout the strip project ensures consistent specifications, including a common strategy on safety factors. Using the thermo-electrical model we can also propose an optimized cooling temperature `ramp' scenario, which equalizes leakage power throughout the lifetime of the experiment while minimizing the TID bump.

We have verified the performance of the thermal network model compared to full FEA and are confident that the agreement is sufficient that the overall accuracy of the model is dominated by other inputs to the model, of which the most likely source of unknown error are limitations in the parametrization of the TID effect available for the model.