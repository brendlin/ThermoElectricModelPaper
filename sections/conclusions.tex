We have developed a model of the ATLAS ITk strip system that is based on the interplay between a thermal and an electrical network model. The set of equations in the model can be numerically solved using standard data analysis software in a short time, allowing for a quick turn-around for systematic studies of the system performance. The complexity of these networks is given by the number of interconnected components between the networks, many of which have a non-linear dependence on the temperature or electrical power. This approach can be easily adopted for any other silicon detector system.

In the case of the ATLAS strip system, several temperature-dependent heat sources had to be modeled. In addition to the sensor leakage current, these are the  radiation-induced increase of the digital front-end power (`TID bump') and the efficiency of the DC-DC conversion system. The outputs of the model give us confidence that the ITk strip system will be thermally stable until the end of LHC Phase-II operation, even with the inclusion of safety factors on key inputs. Furthermore, the model provides information for benchmark system parameters like cooling, supply power and currents in power cables, which is used in the specification of these systems. The use of the model outputs throughout the strip project ensures consistent specifications, including a common strategy on safety factors. Using the thermo-electrical model, we can also propose an optimized cooling temperature `ramp' scenario, which stabilizes leakage power throughout the lifetime of the experiment while minimizing the TID bump.

We have verified the performance of the thermal network model compared to a full FEA treatment, and we are confident that the level of disagreement is smaller than the uncertainty introduced by the model inputs. Among the inputs, the most likely source of uncertainty stems from the limitations in our understanding of the parametrization of the TID effect.
